[
["index.html", "1 Preface", " 1 Preface This is a notebook for reading the book “Statistical Inference (2nd edition). "],
["probability-theory.html", "2 Probability Theory 2.1 Set Theory 2.2 Basics of Probability Theory 2.3 Conditional Probability and Independence 2.4 Random Variables 2.5 Distribution Functions 2.6 Density and Mass Functions 2.7 Miscellanea", " 2 Probability Theory 2.1 Set Theory Definition 1.1.1: Sample space: The set, S, of all possible outcomes of a particular experiment countable uncountable Definition 1.1.2: Event: any collection of possible outcomes of an experiment, that is, any subset of S (including S itself). Union: The union of A and B, written \\(A \\cup B\\), is the set of elements tat belong to either A or B or both. \\(A \\cup B= \\{ x: x\\in A\\text{ or }x \\in B \\}\\) Intersection: The intersection of A and B, written \\(A \\cap B\\), is the set of elements that belong to both A and B. \\(A\\cap B=\\{x: x \\in A\\text{ and }x \\in B\\}\\) Complementation: The complement of A, written \\(A^c\\), is the set of all elements that are not in A. \\(A^c = \\{x: x\\notin A\\}\\) Theorem 1.1.4: For any three events, A, B and C, defined on a sample space S, Commutativity: \\(A \\cup B = B \\cup A\\); \\(A \\cap B = B \\cap A\\) Associativity: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\); \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\) Distributive Laws: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\); \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) DeMorgan’s Laws: \\((A \\cup B)^c = A^c \\cap B^c\\); \\((A \\cap B)^c = A^c \\cup B^c\\) Definition 1.1.5: Two events A and B are disjoint (or mutually exclusive) if \\(A \\cap B = \\emptyset\\). The events \\(A_1, A_2, ...\\) are pairwise disjoint (or mutually exclusive) if \\(A_i \\cap A_j = \\emptyset\\text{ for all }a \\neq b\\). One pairwise disjoint example: \\(A_i = [i, i+1), i =0,1,2,...\\). Definition 1.1.6: If A_1, A_2, … are pairwise disjoint and \\(\\cup _{i=0}^{\\infty} A_i = [0,\\infty) = S\\), then the collection of \\(A_1, A_2, ...\\) forms a partition of S. 2.2 Basics of Probability Theory 2.2.1 Axiomatic（公理的） Foundations Definition 1.2.1: A collection of subsets of S is called sigma algebra (or Borel field), denoted by \\(\\mathcal{B}\\), if it satisfies the following three properties: \\(\\emptyset \\in \\mathcal{B}\\) (the empty set is an element of \\(\\mathcal{B}\\)) If \\(A \\in \\mathcal{B}\\), then \\(A^c \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) is closed under complementation) If \\(A_1, A_2, ... \\in \\mathcal{B}, then \\cup^{\\infty}_{i=1}A_i \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) is closed under coutable unions.) Example 1.2.2 (Sigma algebra-I): If S is finite or countable, then these techinicalities really do not arise, for we define for a given sample space S, \\[\\mathcal{B} = \\text{{all subsets of S, including S itself}}\\] If S has n elements, there are \\(2^n\\) sets in \\(\\mathcal{B}\\). For example, if S={1,2,3}, then \\(\\mathcal{B}\\) = {{1}, {2}, {3}, {1,2},{2,3},{1,3},{1,2,3},\\(\\emptyset\\)}. Definition 1.2.4 (Kolmogorov Axioms): Given a sample space S and an associated sigma algebra \\(\\mathcal{B}\\), a probability function is a function P with domain \\(\\mathcal{B}\\) that satisfies \\(P(A) \\geq 0\\text{ for all } A \\in \\mathcal{B}\\) P(S) = 1 If \\(A_1, A_2, ... \\in \\mathcal{B}\\) are pairwise disjoint, then \\(P(\\cup^{\\infty}_{i=1}A_i) = \\sum_{i=1}^{\\infty}P(A_i)\\) 2.2.2 The Calculus of Probabilities Theorem 1.2.8 If P is a probability function and A is any set in \\(\\mathcal{B}\\), then \\(P(\\emptyset)=0\\) \\(P(A) \\leq 1\\) \\(P(A^c) = 1- P(A)\\) Theorem 1.2.9 If P is a probability function and A and B are any sets in \\(\\mathcal{B}\\), then \\(P(B \\cap A^c) = P(B) -P(A\\cap B)\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B )\\) If \\(A \\subset B\\), then P(A) \\(\\leq\\) P(B) Bonferroni’s Inequality: From the second formula, we can get \\[P(A \\cap B) \\geq P(A) + P(B) - 1\\] Theorem 1.2.11 If P is a probability function, then \\(P(A) = \\sum_{i=1}^\\infty P(A \\cap C_i)\\) for any partition \\(C_1, C_2, ...\\) \\(P(\\cup){i=1}^\\infty \\leq \\sum_{i=1}^\\infty P(A_i)\\) for any sets \\(A_i, A_2, ...\\) (Boole’s Inequality) 2.2.3 Counting Theorem 1.2.14 If a job consistes of k separate tasksm the ith of which can be done in \\(n_i\\) ways, i =1,…,k, then the entire job can be done in \\(n_1 \\times n_2 \\times ...\\times n_k\\) ways Definition 1.2.16 For a positive integer n, n! (read n factorial) is the product of all of the positive integers less than or equal to n. That is \\[n! = n \\times (n-1) \\times (n-2) \\times ... \\times 1\\] Furthermore, we define 0! = 1 Definition 1.2.17 For nonnegative integers n and r, wher n \\(\\geq\\) r, we define the symbol \\(\\binom{r}{n}\\), read n choos r, as \\[\\binom{r}{n} = \\frac{n!}{r!(n-r)!}\\] 2.2.4 Enumerating Outcomes \\[P(A) = \\displaystyle\\sum_{s_i \\in A} P(\\{s_i\\}) = \\displaystyle\\sum_{s_i \\in A}\\frac{1}{N} = \\frac{\\text{# of elements in A}}{\\text{# of elements in S}}\\] 2.3 Conditional Probability and Independence When we update the sample space on new information, we want to be able to update probability calculations or to calculate conditional probabilities. Definition 1.3.2 If A and B are events in S, and P(B) &gt; 0, then the conditional probability of A given B, written P(A|B), is \\[P(A|B) = \\frac{P(A\\cap B)}{P(B)}\\] Theorem 1.3.5 (Bayes’ Rule) Let \\(A_1, A_2, ...\\) be a partition of the sample space, and let B be any set. Then, for each i = 1,2,…, \\[P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{j=1}^{\\infty} P(B|A_j)P(A_j)}\\] Definition 1.3.7 Two events, A and B, are statistically independent if \\[P(A\\cap B) = P(A) P(B)\\] Theorem 1.3.9 If A and B are independent events, then the following pairs are also independent: A and \\(B^c\\) \\(A^c\\) and B \\(A^c\\) and \\(B^c\\) Definition 1.3.12 A collection of events \\(A_1, A_2, ..., A_n\\) are mutually independent if for any subcollection \\(A_{i1}, ...., A_{ik}\\), we have \\[P(\\cap^k_{j=1}A_{ij}) = \\prod_{j=1}^{k}P(A_{ij})\\] 2.4 Random Variables Definition 1.4.1 A random variable is a function from a sample space S into the real numbers. Example 1.4.2 (Random Variables) Examples of random variables Experiment Random variable Toss two dice X = sum of the numbers Toss a coin 25 times X = number of heads in 25 tosses Apply different amouts of fertilizer to corn plants X = yield/acre 2.5 Distribution Functions Definition 1.5.1 The cumulative distribution function or cdf of a random variable X, denoted by \\(F_X(x)\\), is defined by \\[F_X(x) = P_X(X \\leq x)\\], for all x. Theorem 1.5.3 The function F(x) is a cdf if and only if the following three conditions hold: \\(lim_{x \\to -\\infty}F(x) = 0\\) and \\(lim_{x \\to \\infty}F(x) = 1\\) F(x) is a nondecreasing function of x F(x) is right-continuous, that is, for every number \\(x_0\\), \\(lim_{x \\downarrow x_0}F(x) = F(x_0)\\) Definition 1.5.7 A random variable X is continuous if \\(F_X(x)\\) is a continuous function of x. A random variable X is discrete if \\(F_X(x)\\) is a step function of x. Definition 1.5.8 The random variables X and Y are identically distributed if, for every set \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\) Theorem 1.5.10 The following two statments are equivalent: The random variables X and Y are identically distributed \\(F_X(x) = F_Y(x)\\) for every x 2.6 Density and Mass Functions Definition 1.6.1 The probability mass function (pmf) of a discrete random variable X is given by \\[f_X(x) = P(X=x)\\] for all x Definition 1.6.3 The probability density function, or pdf, \\(f_X(x)\\), of a continuous random variable X is the function that satisfies \\[F_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\\] for all x Theorem 1.6.5 A function \\(f_X(x)\\) is a pdf (or pmf) of a random variable X if and only if \\(f_X(x) \\geq 0\\) for all x \\(\\sum_x f_X(x) = 1 (pmf)\\) or \\(\\int_{-\\infty}^{\\infty}f_X(x) dx = 1 (pdf)\\) 2.7 Miscellanea "],
["transformations-and-expectations.html", "3 Transformations and Expectations 3.1 Distributions of Functions of a Random Variable 3.2 Expected Values 3.3 Moments and Moment Generating Functions 3.4 Differentiating Under an Integral Sign 3.5 Miscellanea", " 3 Transformations and Expectations 3.1 Distributions of Functions of a Random Variable If X is a random variable with cdf \\(F_X(x)\\), then any function of X, say g(X), is also a random variable. We set Y=g(X), then \\[P(Y \\in A) = P(g(X) \\in A)\\] Formally, if we write y = g(x), the function g(x) defines a mapping from the original sample space of X, \\(\\mathcal{X}\\), to a new sample space, \\(\\mathcal{Y}\\), the sample space of the random variable Y. That is, \\[g(x): \\mathcal{X} \\to \\mathcal{Y}\\] We associate with g an inverse mapping, denoted by \\(g^{-1)\\), \\[g^{-1}(A) = \\{ x \\in \\mathcal{X}: g(x) \\in A\\}\\] If the random variable Y is now defined by Y = g(X), we can write for any set \\(A \\subset \\mathcal{Y}\\), \\[P(Y \\in A) = P(g(X) \\in A) = P(\\{x\\in\\mathcal{X}: g(x) \\in A\\} = P(X \\in g^{-1}(A))\\] If Y is a discrete random variable, the pmf for Y is \\[f_Y(y) = P(Y=y) = \\sum_{x \\in g^{-1}(y)}P(X=x) =\\sum_{x \\in g^{-1}(y)}f_X(x),\\text{ for }y \\in \\mathcal{Y}\\] It’s easiest to deal with function g(x) that are monotone, that is those that satisfy either increasing or decreasing. It the transformation x –&gt; g(x) is monotone, then it is one-to-one and onto from \\(\\mathcal{X} \\to \\mathcal{Y}\\). Theorem 2.1.3 Let X have cdf \\(F_X(x)\\), let Y = g(X), and let \\(\\mathcal{X} = \\{ x: f_X(x) &gt; 0\\}\\), \\(\\mathcal{Y} = \\{y: y = g(x)\\text{ for some }x \\in \\mathcal{X}\\}\\). If g is an increasing function on \\(\\mathcal{X}\\), \\(F_Y(y) = F_X(g^{-1}(g))\\text{ for }y \\in \\mathcal{Y}\\) If g is a decreasing function on \\(\\mathcal{X}\\) and X is a continuous random variable, \\(F_Y(y) = 1-F_X(g^{-1}(y))\\text{ for }y \\in \\mathcal{Y}\\) 3.2 Expected Values Definition 2.2.1 The expected value or mean of a random varaible g(X), denoted by E(g(X)), is \\[E(g(X)) = \\int_{-\\infty}^{\\infty} g(x)f_X(x)dx\\], if X is continuous \\[E(g(x)) = \\sum_{x \\in \\mathcal{X}} g(x)f_X(x) = \\sum_{x \\in \\mathcal{X}} g(x)P(X=x)\\], if X is discrete, provided that the integral or sum exists. 3.3 Moments and Moment Generating Functions 3.4 Differentiating Under an Integral Sign 3.5 Miscellanea "],
["common-families-of-distributions.html", "4 Common Families of Distributions 4.1 Introduction 4.2 Discrete Distributions 4.3 Continuous Distributions 4.4 Exponential Families 4.5 Location and Scale Families 4.6 Inequalities and Identities 4.7 Miscellanea", " 4 Common Families of Distributions 4.1 Introduction 4.2 Discrete Distributions 4.3 Continuous Distributions 4.4 Exponential Families 4.5 Location and Scale Families 4.6 Inequalities and Identities 4.6.1 Probability Inequalities 4.6.2 Identities 4.7 Miscellanea "],
["multiple-random-variables.html", "5 Multiple Random Variables 5.1 Joint and Marginal Distributions 5.2 Conditional Distributions and Independence 5.3 Bivariate Transformations 5.4 Hierarchical Models and Mixtrue Distributions 5.5 Covariance and Correlation 5.6 Multivariate Distributions 5.7 Inequalities 5.8 Miscellanea", " 5 Multiple Random Variables 5.1 Joint and Marginal Distributions 5.2 Conditional Distributions and Independence 5.3 Bivariate Transformations 5.4 Hierarchical Models and Mixtrue Distributions 5.5 Covariance and Correlation 5.6 Multivariate Distributions 5.7 Inequalities 5.7.1 Numerical Inequalities 5.7.2 Functional Inequalities 5.8 Miscellanea "],
["properties-of-a-random-sample.html", "6 Properties of a Random Sample 6.1 Basic Concepts of Random Samples 6.2 Sums of Random Variables from a Random Sample 6.3 Sampling from the Normal Distribution 6.4 Order Statistics 6.5 Convergence Concepts 6.6 Generating a Random Sample 6.7 Miscellance", " 6 Properties of a Random Sample 6.1 Basic Concepts of Random Samples 6.2 Sums of Random Variables from a Random Sample 6.3 Sampling from the Normal Distribution 6.3.1 Properties of the Sample Mean and Variance 6.3.2 The Derived Distributions: Student’s t and Snedecor’s F 6.4 Order Statistics 6.5 Convergence Concepts 6.5.1 Convergence in Probability 6.5.2 Almost Sure Convergence 6.5.3 Convergence in Distribution 6.5.4 The Delta Method 6.6 Generating a Random Sample 6.6.1 Direct Methods 6.6.2 Indirect Methods 6.6.3 The Accept/Reject Algorithm 6.7 Miscellance "],
["principles-of-data-reduction.html", "7 Principles of Data Reduction 7.1 Introduction 7.2 The Sufficiency Principle 7.3 The Likelihood Principle 7.4 The Equivariance Principle 7.5 Miscelllanea", " 7 Principles of Data Reduction 7.1 Introduction 7.2 The Sufficiency Principle 7.2.1 Sufficient Statistics 7.2.2 Minimal Sufficient Statistics 7.2.3 Ancillary Statistics 7.2.4 Sufficient, Ancillary, and Complete Statistics 7.3 The Likelihood Principle 7.3.1 The Likelihood Function 7.3.2 The Formal Likelihood Principe 7.4 The Equivariance Principle 7.5 Miscelllanea "],
["point-estimation.html", "8 Point Estimation 8.1 Introduction 8.2 Methods of Finding Estimators 8.3 Methods of Evaluating Estimators 8.4 Miscellanea", " 8 Point Estimation 8.1 Introduction 8.2 Methods of Finding Estimators 8.2.1 Method of Moments 8.2.2 Maximum Likelihood Estimators 8.2.3 Bayes Estimators 8.2.4 The EM Algorithm 8.3 Methods of Evaluating Estimators 8.3.1 Mean Squared Error 8.3.2 Best Unbiased Estimators 8.3.3 Sufficiency and Unbiasedness 8.3.4 Loss Function Optimality 8.4 Miscellanea "],
["hypothesis-testing.html", "9 Hypothesis Testing 9.1 Introduction 9.2 Methods of Finding Tests 9.3 Methods of Evaluating Tests 9.4 Miscellanea", " 9 Hypothesis Testing 9.1 Introduction 9.2 Methods of Finding Tests 9.2.1 Likelihood Ratio Tests 9.2.2 Bayesian Tests 9.2.3 Union-Intersection and Intersection-Union Tests 9.3 Methods of Evaluating Tests 9.3.1 Error Probabilities and the Power Function 9.3.2 Most Powerful Tests 9.3.3 Sizes of Union-Intersection and Intersection-Union Tests 9.3.4 p-Values 9.3.5 Loss Function Optimality 9.4 Miscellanea "],
["interval-estimation.html", "10 Interval Estimation 10.1 Introduction 10.2 Methods of Finding Interval Estimators 10.3 Methods of Evaluating Interval Estimators 10.4 Miscllanea", " 10 Interval Estimation 10.1 Introduction 10.2 Methods of Finding Interval Estimators 10.2.1 Inverting a Test Statistic 10.2.2 Pivotal Quantities 10.2.3 Pivoting the CDF 10.2.4 Bayesian Intervals 10.3 Methods of Evaluating Interval Estimators 10.3.1 Size and Coverage Probability 10.3.2 Test-Related Optimality 10.3.3 Bayesian Optimality 10.3.4 Loss Function Optimality 10.4 Miscllanea "],
["asymptotic-evaluations.html", "11 Asymptotic Evaluations 11.1 Point Estimation 11.2 Robustness 11.3 Hypothesis Testing 11.4 Interval Estimation 11.5 Miscellanea", " 11 Asymptotic Evaluations 11.1 Point Estimation 11.1.1 Consistency 11.1.2 Efficiency 11.1.3 Calculations and Comparisons 11.1.4 Bootstrap Standard Errors 11.2 Robustness 11.2.1 The Mean and the Median 11.2.2 M-Estimators 11.3 Hypothesis Testing 11.3.1 Asymptotic Distribution of LRTs 11.3.2 Other Large-Sample Tests 11.4 Interval Estimation 11.4.1 Approximate Maximum Likelihood Intervals 11.4.2 Other Large-Sample Intervals 11.5 Miscellanea "],
["analysis-of-variance-and-regression.html", "12 Analysis of Variance and Regression 12.1 Introduction 12.2 Oneway Analysis of Variance 12.3 Simple Linear Regression 12.4 Miscellanea", " 12 Analysis of Variance and Regression 12.1 Introduction 12.2 Oneway Analysis of Variance 12.2.1 Model and Distribution Assumptions 12.2.2 The Classical ANOVA Hypothesis 12.2.3 Inferences Regarding Linear Combinations of Means 12.2.4 The ANOVA F Test 12.2.5 Simultaneous Estimation of Contrasts 12.2.6 Partitioning Sums of Squares 12.3 Simple Linear Regression 12.3.1 Least Squares: A Mathematical Solution 12.3.2 Best Linear Unbiased Estimators: A Statistical Solution 12.3.3 Models and Distribution Assumptions 12.3.4 Estimation and Testing with Normal Erros 12.3.5 Estimation and Prediction at a Specified x = x0 12.3.6 Simultaneous Estimation and Confidence Bands 12.4 Miscellanea "],
["regression-models.html", "13 Regression Models 13.1 Introduction 13.2 Regression with Errors in Variables 13.3 Logistic Regression 13.4 Robust Regression 13.5 Miscellanea", " 13 Regression Models 13.1 Introduction 13.2 Regression with Errors in Variables 13.2.1 Functional and Structural Relationships 13.2.2 A Least Squares Solution 13.2.3 Maximum Likelihood Estimation 13.2.4 Confidence Sets 13.3 Logistic Regression 13.3.1 The Model 13.3.2 Estimation 13.4 Robust Regression 13.5 Miscellanea "]
]
