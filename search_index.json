[["index.html", "Preface", " Preface This is a notebook for reading the book \"Statistical Inference (2nd edition). "],["probability-theory.html", "1 Probability Theory 1.1 Set Theory 1.2 Basics of Probability Theory 1.3 Conditional Probability and Independence 1.4 Random Variables 1.5 Distribution Functions 1.6 Density and Mass Functions 1.7 Miscellanea", " 1 Probability Theory 1.1 Set Theory Definition 1.1.1: Sample space: The set, S, of all possible outcomes of a particular experiment countable uncountable Definition 1.1.2: Event: any collection of possible outcomes of an experiment, that is, any subset of S (including S itself). Union: The union of A and B, written \\(A \\cup B\\), is the set of elements tat belong to either A or B or both. \\(A \\cup B= \\{ x: x\\in A\\text{ or }x \\in B \\}\\) Intersection: The intersection of A and B, written \\(A \\cap B\\), is the set of elements that belong to both A and B. \\(A\\cap B=\\{x: x \\in A\\text{ and }x \\in B\\}\\) Complementation: The complement of A, written \\(A^c\\), is the set of all elements that are not in A. \\(A^c = \\{x: x\\notin A\\}\\) Theorem 1.1.4: For any three events, A, B and C, defined on a sample space S, Commutativity: \\(A \\cup B = B \\cup A\\); \\(A \\cap B = B \\cap A\\) Associativity: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\); \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\) Distributive Laws: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\); \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\) DeMorgan’s Laws: \\((A \\cup B)^c = A^c \\cap B^c\\); \\((A \\cap B)^c = A^c \\cup B^c\\) Definition 1.1.5: Two events A and B are disjoint (or mutually exclusive) if \\(A \\cap B = \\emptyset\\). The events \\(A_1, A_2, ...\\) are pairwise disjoint (or mutually exclusive) if \\(A_i \\cap A_j = \\emptyset\\text{ for all }a \\neq b\\). One pairwise disjoint example: \\(A_i = [i, i+1), i =0,1,2,...\\). Definition 1.1.6: If A_1, A_2, … are pairwise disjoint and \\(\\cup _{i=0}^{\\infty} A_i = [0,\\infty) = S\\), then the collection of \\(A_1, A_2, ...\\) forms a partition of S. 1.2 Basics of Probability Theory 1.2.1 Axiomatic（公理的） Foundations Definition 1.2.1: A collection of subsets of S is called sigma algebra (or Borel field), denoted by \\(\\mathcal{B}\\), if it satisfies the following three properties: \\(\\emptyset \\in \\mathcal{B}\\) (the empty set is an element of \\(\\mathcal{B}\\)) If \\(A \\in \\mathcal{B}\\), then \\(A^c \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) is closed under complementation) If \\(A_1, A_2, ... \\in \\mathcal{B}, then \\cup^{\\infty}_{i=1}A_i \\in \\mathcal{B}\\) (\\(\\mathcal{B}\\) is closed under coutable unions.) Example 1.2.2 (Sigma algebra-I): If S is finite or countable, then these techinicalities really do not arise, for we define for a given sample space S, \\[\\mathcal{B} = \\text{{all subsets of S, including S itself}}\\] If S has n elements, there are \\(2^n\\) sets in \\(\\mathcal{B}\\). For example, if S={1,2,3}, then \\(\\mathcal{B}\\) = {{1}, {2}, {3}, {1,2},{2,3},{1,3},{1,2,3},\\(\\emptyset\\)}. Definition 1.2.4 (Kolmogorov Axioms): Given a sample space S and an associated sigma algebra \\(\\mathcal{B}\\), a probability function is a function P with domain \\(\\mathcal{B}\\) that satisfies \\(P(A) \\geq 0\\text{ for all } A \\in \\mathcal{B}\\) P(S) = 1 If \\(A_1, A_2, ... \\in \\mathcal{B}\\) are pairwise disjoint, then \\(P(\\cup^{\\infty}_{i=1}A_i) = \\sum_{i=1}^{\\infty}P(A_i)\\) 1.2.2 The Calculus of Probabilities Theorem 1.2.8 If P is a probability function and A is any set in \\(\\mathcal{B}\\), then \\(P(\\emptyset)=0\\) \\(P(A) \\leq 1\\) \\(P(A^c) = 1- P(A)\\) Theorem 1.2.9 If P is a probability function and A and B are any sets in \\(\\mathcal{B}\\), then \\(P(B \\cap A^c) = P(B) -P(A\\cap B)\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B )\\) If \\(A \\subset B\\), then P(A) \\(\\leq\\) P(B) Bonferroni’s Inequality: From the second formula, we can get \\[P(A \\cap B) \\geq P(A) + P(B) - 1\\] Theorem 1.2.11 If P is a probability function, then \\(P(A) = \\sum_{i=1}^\\infty P(A \\cap C_i)\\) for any partition \\(C_1, C_2, ...\\) \\(P(\\cup){i=1}^\\infty \\leq \\sum_{i=1}^\\infty P(A_i)\\) for any sets \\(A_i, A_2, ...\\) (Boole’s Inequality) 1.2.3 Counting Theorem 1.2.14 If a job consistes of k separate tasksm the ith of which can be done in \\(n_i\\) ways, i =1,…,k, then the entire job can be done in \\(n_1 \\times n_2 \\times ...\\times n_k\\) ways Definition 1.2.16 For a positive integer n, n! (read n factorial) is the product of all of the positive integers less than or equal to n. That is \\[n! = n \\times (n-1) \\times (n-2) \\times ... \\times 1\\] Furthermore, we define 0! = 1 Definition 1.2.17 For nonnegative integers n and r, wher n \\(\\geq\\) r, we define the symbol \\(\\binom{r}{n}\\), read n choos r, as \\[\\binom{r}{n} = \\frac{n!}{r!(n-r)!}\\] 1.2.4 Enumerating Outcomes \\[P(A) = \\displaystyle\\sum_{s_i \\in A} P(\\{s_i\\}) = \\displaystyle\\sum_{s_i \\in A}\\frac{1}{N} = \\frac{\\text{# of elements in A}}{\\text{# of elements in S}}\\] 1.3 Conditional Probability and Independence When we update the sample space on new information, we want to be able to update probability calculations or to calculate conditional probabilities. Definition 1.3.2 If A and B are events in S, and P(B) &gt; 0, then the conditional probability of A given B, written P(A|B), is \\[P(A|B) = \\frac{P(A\\cap B)}{P(B)}\\] Theorem 1.3.5 (Bayes’ Rule) Let \\(A_1, A_2, ...\\) be a partition of the sample space, and let B be any set. Then, for each i = 1,2,…, \\[P(A_i|B) = \\frac{P(B|A_i)P(A_i)}{\\sum_{j=1}^{\\infty} P(B|A_j)P(A_j)}\\] Definition 1.3.7 Two events, A and B, are statistically independent if \\[P(A\\cap B) = P(A) P(B)\\] Theorem 1.3.9 If A and B are independent events, then the following pairs are also independent: A and \\(B^c\\) \\(A^c\\) and B \\(A^c\\) and \\(B^c\\) Definition 1.3.12 A collection of events \\(A_1, A_2, ..., A_n\\) are mutually independent if for any subcollection \\(A_{i1}, ...., A_{ik}\\), we have \\[P(\\cap^k_{j=1}A_{ij}) = \\prod_{j=1}^{k}P(A_{ij})\\] 1.4 Random Variables Definition 1.4.1 A random variable is a function from a sample space S into the real numbers. Example 1.4.2 (Random Variables) Examples of random variables Experiment Random variable Toss two dice X = sum of the numbers Toss a coin 25 times X = number of heads in 25 tosses Apply different amouts of fertilizer to corn plants X = yield/acre 1.5 Distribution Functions Definition 1.5.1 The cumulative distribution function or cdf of a random variable X, denoted by \\(F_X(x)\\), is defined by \\[F_X(x) = P_X(X \\leq x)\\], for all x. Theorem 1.5.3 The function F(x) is a cdf if and only if the following three conditions hold: \\(lim_{x \\to -\\infty}F(x) = 0\\) and \\(lim_{x \\to \\infty}F(x) = 1\\) F(x) is a nondecreasing function of x F(x) is right-continuous, that is, for every number \\(x_0\\), \\(lim_{x \\downarrow x_0}F(x) = F(x_0)\\) Definition 1.5.7 A random variable X is continuous if \\(F_X(x)\\) is a continuous function of x. A random variable X is discrete if \\(F_X(x)\\) is a step function of x. Definition 1.5.8 The random variables X and Y are identically distributed if, for every set \\(A \\in \\mathcal{B}^1, P(X \\in A) = P(Y \\in A)\\) Theorem 1.5.10 The following two statments are equivalent: The random variables X and Y are identically distributed \\(F_X(x) = F_Y(x)\\) for every x 1.6 Density and Mass Functions Definition 1.6.1 The probability mass function (pmf) of a discrete random variable X is given by \\[f_X(x) = P(X=x)\\] for all x Definition 1.6.3 The probability density function, or pdf, \\(f_X(x)\\), of a continuous random variable X is the function that satisfies \\[F_X(x) = \\int_{-\\infty}^{x} f_X(t) dt\\] for all x Theorem 1.6.5 A function \\(f_X(x)\\) is a pdf (or pmf) of a random variable X if and only if \\(f_X(x) \\geq 0\\) for all x \\(\\sum_x f_X(x) = 1 (pmf)\\) or \\(\\int_{-\\infty}^{\\infty}f_X(x) dx = 1 (pdf)\\) 1.7 Miscellanea "],["transformations-and-expectations.html", "2 Transformations and Expectations 2.1 Distributions of Functions of a Random Variable 2.2 Expected Values 2.3 Moments and Moment Generating Functions 2.4 Differentiating Under an Integral Sign 2.5 Miscellanea", " 2 Transformations and Expectations 2.1 Distributions of Functions of a Random Variable If X is a random variable with cdf \\(F_X(x)\\), then any function of X, say g(X), is also a random variable. We set Y=g(X), then for any set A \\[P(Y \\in A) = P(g(X) \\in A)\\] Formally, if we write y = g(x), the function g(x) defines a mapping from the original sample space of X, \\(\\mathcal{X}\\), to a new sample space, \\(\\mathcal{Y}\\), the sample space of the random variable Y. That is, \\[g(x): \\mathcal{X} \\to \\mathcal{Y}\\] We associate with g an inverse mapping, denoted by \\(g^{-1}\\), \\[g^{-1}(A) = \\{ x \\in \\mathcal{X}: g(x) \\in A\\}\\] If the random variable Y is now defined by Y = g(X), we can write for any set \\(A \\subset \\mathcal{Y}\\), \\[P(Y \\in A) = P(g(X) \\in A) = P(\\{x\\in\\mathcal{X}: g(x) \\in A\\} = P(X \\in g^{-1}(A))\\] If Y is a discrete random variable, the pmf for Y is \\[f_Y(y) = P(Y=y) = \\sum_{x \\in g^{-1}(y)}P(X=x) =\\sum_{x \\in g^{-1}(y)}f_X(x),\\text{ for }y \\in \\mathcal{Y}\\] It’s easiest to deal with function g(x) that are monotone, that is those that satisfy either increasing or decreasing. It the transformation x –&gt; g(x) is monotone, then it is one-to-one and onto from \\(\\mathcal{X} \\to \\mathcal{Y}\\). Example 2.1.1 Binomial transformation Example 2.1.2 Uniform transformation Theorem 2.1.3 Let X have cdf \\(F_X(x)\\), let Y = g(X), and let \\(\\mathcal{X} = \\{ x: f_X(x) &gt; 0\\}\\), \\(\\mathcal{Y} = \\{y: y = g(x)\\text{ for some }x \\in \\mathcal{X}\\}\\). If g is an increasing function on \\(\\mathcal{X}\\), \\(F_Y(y) = F_X(g^{-1}(g))\\text{ for }y \\in \\mathcal{Y}\\) If g is a decreasing function on \\(\\mathcal{X}\\) and X is a continuous random variable, \\(F_Y(y) = 1-F_X(g^{-1}(y))\\text{ for }y \\in \\mathcal{Y}\\) Example 2.1.4 Uniform-exponenetial relationship-I Theorem 2.1.5 Let X have pdf \\(f_X(x)\\) and let \\(Y=g(X)\\), where g is a monotone function. Let \\(\\mathcal{X} = \\{ x: f_X(x) &gt; 0\\}\\), \\(\\mathcal{Y} = \\{y: y = g(x)\\text{ for some }x \\in \\mathcal{X}\\}\\). Suppose that \\(f_X(x)\\) is continuous on \\(\\mathcal{X}\\) and that \\(g^{-1}(y)\\) has a continuous derivative on \\(\\mathcal{Y}\\). THen the pdf of Y is given by \\[f_Y(y)= \\begin{cases}f_X(g^{-1}(y))|\\frac{d}{dy}g^{-1}(y)| &amp; \\quad y \\in \\mathcal{Y} \\\\ 0 &amp; \\quad \\text{otherwise}\\end{cases}\\] Example 2.1.6 Inverted gamma pdf Example 2.1.7 Square transformation Example 2.1.9 Normal-chi squared relationship Theorem 2.1.10 Probability integral transformation Let X have continuous cdf \\(F_X(x)\\) and define the random variable Y as Y = \\(F_X(X)\\). Then Y is uniformly distributed on (0,1), that is, \\(P(Y \\leq y) = y, 0&lt;y&lt;1\\). 2.2 Expected Values Definition 2.2.1 The expected value or mean of a random varaible g(X), denoted by E(g(X)), is \\[E(g(X)) = \\int_{-\\infty}^{\\infty} g(x)f_X(x)dx\\], if X is continuous \\[E(g(x)) = \\sum_{x \\in \\mathcal{X}} g(x)f_X(x) = \\sum_{x \\in \\mathcal{X}} g(x)P(X=x)\\], if X is discrete, provided that the integral or sum exists. Note: The proof of expectation of binomial distribution can be found here. Theorem 2.2.5 Let X be a random variable and let a, b and c be constants. Then for any functions \\(g_1(x)\\) and \\(g_2(x)\\) whose expectations exist, \\(E(ag_1(X) + bg_2(X) + c) = aE(g_1(X))+bE(g_2(X)) + c\\) If \\(g_1(x) \\geq 0\\) for all x, then \\(E(g_1(X)) \\geq 0\\) If \\(g_1(x) \\geq g_2(X)\\) for all x, then \\(E(g_1(X)) \\geq E(g_2(X))\\) If \\(a \\leq g_1(x) \\leq b\\) for all x, then \\(a \\leq E(g_1(x)) \\leq b\\) 2.3 Moments and Moment Generating Functions Definition 2.3.1 For each integer n, the nth moment of X (or \\(F_X(x)\\)), \\(\\mu^{&#39;}_n = E(X^{n})\\). The nth central moment of X, \\(\\mu_n = E((X-\\mu)^{n})\\), where \\(\\mu = \\mu_1^{&#39;} = E(X)\\). Definition 2.3.2 The variance of a random variable X is its second central moment, \\(Var(X) = E((X-E(X))^2)\\). The positive square root of Var(X) is the sandard deviation of X. Theorem 2.3.4 If X is a random variable with finite variance, then for any constants a and b, \\[Var(aX + b) = a^2 Var(X)\\] Note: The proof of variance of binomial distribution can be found here. Definition 2.3.6 Let X be a random variable with cdf \\(F_X\\). The moment generating function(mgf) of X (or \\(F_X\\)), denoted by \\(M_X(t)\\), is \\[M_X(t) = E(e^{tX})\\] provided that the epectation exists for t in some neighborhood of 0. Theorem 2.3.7 If X has mgf \\(M_X(t)\\), then \\[E(X^n) = M_X^{(n)}(0)\\] where we define \\[M_X^{(n)}(0) = \\left.\\frac{d^n}{dt^n}M_X(t)\\right|_{t=0}\\] That is, the nth moment is equal to the nth derivative of \\(M_X(t)\\) evaluated at t=0. kernel: the kernel of a function is the main part of the function, the part that remains when constants are disregarded. 2.4 Differentiating Under an Integral Sign 2.5 Miscellanea "],["common-families-of-distributions.html", "3 Common Families of Distributions 3.1 Introduction 3.2 Discrete Distributions 3.3 Continuous Distributions 3.4 Exponential Families 3.5 Location and Scale Families 3.6 Inequalities and Identities 3.7 Miscellanea", " 3 Common Families of Distributions 3.1 Introduction Statistical distributions are used to model populations; as such, we usualy deal with a family of distributions rather than a single distribution. This family is indexed by one or more parameters, which allow us to vary certian characteristics of the distribution while staying with one functional form. 3.2 Discrete Distributions A random variable X is said to have a discrete distribution if the range of X, the sample space, is countable. Discrete Uniform Distribution A random variable X has a discrete uniform (1,N) distribution if \\[P(X=x|N) = \\frac{1}{N}, x = 1,2,3,...,N\\], where N is a specified integer. \\[E(X) = \\sum_{x=1}^N x \\frac{1}{N} = \\frac{N+1}{2} \\] \\[Var(X) = E(X^2) - [E(X)]^2 = \\frac{(N+1)(2N+1)}{6} - (\\frac{N+1}{2})^2 = \\frac{(N+1)(N-1)}{12}\\] Hypergeometric Distribution Binomial Distribution Poisson Distribution Negative Binomial Distribution Geometric Distribution 3.3 Continuous Distributions Uniform Distribution Gamma Distribution Normal Distribution Beta Distribution Cauchy Distribution Lognormal Distribution Double Exponential Distribution 3.4 Exponential Families A family of pdfs or pmfs is called an exponential family if it can be expressed as \\[f(x|\\boldsymbol{\\theta}) = h(x)c(\\boldsymbol{\\theta})exp(\\sum_{i=1}^kw_i(\\boldsymbol{\\theta})t_i(x))\\]. Here \\(h(x) \\geq 0\\) and \\(t_1(x),...,t_k(x)\\) are real-valued functions of the observation x (they cannot depend on \\(\\boldsymbol{\\theta}\\)), and \\(c(\\boldsymbol{\\theta}) \\geq 0\\) and \\(w_1(\\boldsymbol{\\theta}), ..., w_k(\\boldsymbol{\\theta})\\) are real-valued functions of the possible vector-valued parameter \\(\\boldsymbol{\\theta}\\) (they cannot depend on x). Many common families are exponential families, including the continuous families (normal, gamma, and beta), and the discrete families (binomial, Poisson, and negative binomial). 3.5 Location and Scale Families Three techniques for constructing families of distributions. The three types of families are called location families, scale families, and location-scale families. 3.6 Inequalities and Identities 3.6.1 Probability Inequalities The most famous, and perhaps most useful, probability inequality is Chebychev’s Inequality. 3.6.2 Identities 3.7 Miscellanea "],["multiple-random-variables.html", "4 Multiple Random Variables 4.1 Joint and Marginal Distributions 4.2 Conditional Distributions and Independence 4.3 Bivariate Transformations 4.4 Hierarchical Models and Mixtrue Distributions 4.5 Covariance and Correlation 4.6 Multivariate Distributions 4.7 Inequalities 4.8 Miscellanea", " 4 Multiple Random Variables 4.1 Joint and Marginal Distributions The probability models and computation of probability for events involving only one random variable are called univariate models. The probability models that involve more than one random variable are called multivariate models. The models involving two random variables are called bivariate models. Definition 4.1.1 An n-dimensional random vector is a function from a sample space S into \\(R^n\\), n-dimensional Euclidean space. Definition 4.1.3 Let (X,Y) be a discrete bivariate random vector. Then the function \\(f(x,y)\\) from \\(R^2\\) into R defined by \\(f(x,y) = P(X=x,y=y)\\) is called the joint probability mass function or joint pmf of (X,Y). If it is necessary to stress the fact that \\(f\\) is the joint pmf of the vector (X,Y) rather than some other vector, the notation \\(f_{X,Y}(x,y)\\) will be used. Theorem 4.1.6 Let (X,Y) be a discrete bivariate random vector with joint pmf \\(f_{X,Y}(x,y)\\). Then the marginal pmfs of X and Y, \\(f_X(x) = P(X=x)\\) and \\(f_Y(y)=P(Y=y)\\), are given by \\[f_X(x) = \\sum_{y \\in R} f_{X,Y}(x,y)\\text{ and }f_Y(y) = \\sum_{x \\in R} f_{X,Y}(x,y)\\] Definition 4.1.10 A function \\(f(x,y)\\) from \\(R^2\\) into R is called a joint probability density function or joint pdf of the continuous bivariate random vector (X,Y) if, for every \\(A \\subset R^2\\), \\[P((X,Y) \\in A) = \\int_A \\int f(x,y)dxdy\\] The marginal probability density functions of X and Y are given by \\[f_X(x) = \\int_{-\\infty}^{\\infty}f(x,y)dy,\\text{ } -\\infty &lt; x &lt; \\infty\\] \\[f_Y(y) = \\int_{-\\infty}^{\\infty}f(x,y)dx,\\text{ }-\\infty&lt; y&lt; \\infty\\] The joint cdf (cumulative distribution function) is the function F(x,y) defined by for a discrete random vector, \\[F(x,y) = P(X \\leq x, Y \\leq y)\\] or for a continuous bivariate random vector, \\[F(x,y) = \\int_{-\\infty}^x\\int_{-\\infty}^y f(s,t) dt ds\\] 4.2 Conditional Distributions and Independence Definition 4.2.1 Let (X,Y) be a discrete bivariate random vector with joint pmf f(x,y) and marginal pmfs \\(f_X(x)\\) and \\(f_Y(y)\\). For any x such that \\(P(X=x)=f_X(x) &gt; 0\\), the conditional pmf of Y given that X=x is the function of y denoted by f(y|x) and definied by \\[f(y|x) = P(Y=y|X=x) = \\frac{f(x,y)}{f_X(x)}\\] Definition 4.2.3 Let (X,Y) be a continuous bivariate random vector with joint pdf f(x,y) and marginal pdfs \\(f_X(x)\\) and \\(f_Y(y)\\). For any x such that \\(f_X(x) &gt; 0\\), the conditional pdf of Y given that X=x is the function of y denoted by f(y|x) and defined by \\[f(y|x) = \\frac{f(x,y)}{f_X(x)}\\] Definition 4.2.5 Let (X,Y) be a bivariate random vector with joint pdf or pmf f(x,y) and marginal pdfs or pmfs \\(f_X(x)\\) and \\(f_Y(y)\\). Then X and Y are called independent random variables if, for every \\(x \\in R\\text{ and }y \\in R\\), \\[f(x,y) = f_X(x)f_Y(y)\\] Theorem 4.2.10 Let X and Y be independent random variables. For any \\(A \\subset R\\text{ and } B \\subset R\\), \\(P(X \\in A, Y \\in B) = P(X \\in A) P(Y \\in B)\\); that is, the events {X A} and {Y B} are independent events. Let g(x) be a function only of x and h(y) be a function only of y. Then \\(E(g(X)h(Y)) = E(g(X))E(h(Y))\\). Theorem 4.2.12 Let X and Y be independet random variables with moment generating functions \\(M_X(t)\\) and \\(M_Y(t)\\). Then the moment generating function of the random variable Z = X + Y is given by \\(M_Z(t) = M_X(t)M_Y(t)\\) Theorem 4.2.14 Let \\(X \\sim n(\\mu, \\sigma^2)\\text{ and }Y \\sim n(\\gamma, \\tau^2)\\) be independent normal random variables. Then the random variable Z = X + Y has a \\(n(\\mu+\\gamma, \\sigma^2 + \\tau^2)\\) distribution. 4.3 Bivariate Transformations Let \\((X,Y)\\) be a bivariate random vector with a know probability distribution. Now consider a new bivariate random vector \\((U,V)\\) defined by \\(U=g_1(X,Y)\\) and \\(V=g_2(X,Y)\\), where \\(g_1(x,y)\\) and \\(g_2(x,y)\\) are some specified function. Theorem 4.3.2 If \\(X \\sim Poisson(\\theta)\\) and \\(Y \\sim Poisson(\\lambda)\\), and X and Y are independent, then \\(X+Y \\sim Poisson(\\theta+\\lambda)\\) Consider \\((X,Y)\\) is a continuous random vector with joint pdf \\(f_{X,Y}(x,y)\\), assume the transformation \\(u=g_1(x,y)\\) and \\(v=g_2(x,y)\\) are one-to-one transformation, denote the inverse transformation by \\(x=h_1(u,v)\\) and \\(y=h_2)u,v\\), the joint pdf of (U,V) is given by Equation 4.3.2 \\(f_{U,V}(u,v)=f_{X,Y}(h_1(u,v), h2(u,v))|J|\\) , where J is the determinant of a matrix of partial derivateives (Jacobian of the transofrmations) \\[J=\\begin{vmatrix} \\frac{\\partial x}{\\partial u} &amp; \\frac{\\partial x}{\\partial v} \\\\ \\frac{\\partial y}{\\partial u} &amp; \\frac{\\partial y}{\\partial v} \\end{vmatrix}=\\frac{\\partial x}{\\partial u} \\frac{\\partial y}{\\partial v}-\\frac{\\partial x}{\\partial v} \\frac{\\partial y}{\\partial u}\\] Theorem 4.3.5 Let X and Y be independent random variables. Let \\(g(x)\\) be a function only of x and \\(h(y)\\) be a function only of y. Then the random variables \\(U=g(X)\\) and \\(V=h(Y)\\) are independent. Example 4.3.6 (Distribution of the ratio of normal variables) The ratio of two independent standard normal random variables is a Cauchy random variable. 4.4 Hierarchical Models and Mixtrue Distributions Example 4.4.1 (Binomial-Poisson hierarchy) Complicated processes may be modeled by a sequence of relatively simple models placed in a hierarchy Dealing with the hierarchy, dealing with conditional and marginal distributions Theorem 4.4.3 If X and Y are any two random variables, then \\[EX=E(E(X|Y))\\] , provided that the expectations exist Mixture distribution refers to a distribution arising from a hierarchical structure. Definition 4.4.4 A random variable X is said to have a mixture distribution if the distribution of X depends on a quantity that also has a distribution. the hierarchy at two stages, multistage hierarchy noncentral chi-squared distribution the pdf for p degrees of freedom and noncentrality parameter \\(\\lambda\\) is given by \\[f(x|\\lambda, p)=\\sum_{k=0}^{\\infty}\\frac{x^{p/2+k-1}e^{-x/2}}{\\Gamma(p/2+k)2^{p/2+k}}\\frac{\\lambda ^ke^{-\\lambda}}{k!}\\] This can be seen as a mixture distribution, made up of central chi-squared densities and Poisson distributions. That is \\[X|K \\sim \\chi^2_{p+2K}\\] \\[K \\sim Poisson(\\lambda)\\] So \\[EX = E(E(X|K))=E(p+2K)=p+2\\lambda\\] Theorem 4.4.7 (Conditional variance identity) For any two random variables X and Y, \\[Var X = E(Var(X|Y))+Var(E(X|Y))\\] 4.5 Covariance and Correlation covariance and correlation: two numerical measures of the strength of a relationship between two random variables Notation: \\(EX=\\mu_X\\), \\(EY=\\mu_Y\\), \\(Var X=\\sigma^2_X\\), and \\(Var Y=\\sigma^2_Y\\) Definition 4.5.1 The covariance of X and Y is the number defined by \\[Cov(X,Y)=E((X-\\mu_X)(Y-\\mu_Y))\\] Definition 4.5.2 The correlation of X and Y is the number defined by \\[\\rho_{XY}=\\frac{Cov(X,Y)}{\\sigma_X\\sigma_Y}\\] , where the value \\(\\rho_{XY}\\) is called the correlation coefficient. 4.6 Multivariate Distributions 4.7 Inequalities 4.7.1 Numerical Inequalities 4.7.2 Functional Inequalities 4.8 Miscellanea "],["properties-of-a-random-sample.html", "5 Properties of a Random Sample 5.1 Basic Concepts of Random Samples 5.2 Sums of Random Variables from a Random Sample 5.3 Sampling from the Normal Distribution 5.4 Order Statistics 5.5 Convergence Concepts 5.6 Generating a Random Sample 5.7 Miscellance", " 5 Properties of a Random Sample 5.1 Basic Concepts of Random Samples 5.2 Sums of Random Variables from a Random Sample 5.3 Sampling from the Normal Distribution 5.3.1 Properties of the Sample Mean and Variance 5.3.2 The Derived Distributions: Student’s t and Snedecor’s F 5.4 Order Statistics 5.5 Convergence Concepts 5.5.1 Convergence in Probability 5.5.2 Almost Sure Convergence 5.5.3 Convergence in Distribution 5.5.4 The Delta Method 5.6 Generating a Random Sample 5.6.1 Direct Methods 5.6.2 Indirect Methods 5.6.3 The Accept/Reject Algorithm 5.7 Miscellance "],["principles-of-data-reduction.html", "6 Principles of Data Reduction 6.1 Introduction 6.2 The Sufficiency Principle 6.3 The Likelihood Principle 6.4 The Equivariance Principle 6.5 Miscelllanea", " 6 Principles of Data Reduction 6.1 Introduction 6.2 The Sufficiency Principle 6.2.1 Sufficient Statistics 6.2.2 Minimal Sufficient Statistics 6.2.3 Ancillary Statistics 6.2.4 Sufficient, Ancillary, and Complete Statistics 6.3 The Likelihood Principle 6.3.1 The Likelihood Function 6.3.2 The Formal Likelihood Principe 6.4 The Equivariance Principle 6.5 Miscelllanea "],["point-estimation.html", "7 Point Estimation 7.1 Introduction 7.2 Methods of Finding Estimators 7.3 Methods of Evaluating Estimators 7.4 Miscellanea", " 7 Point Estimation 7.1 Introduction 7.2 Methods of Finding Estimators 7.2.1 Method of Moments 7.2.2 Maximum Likelihood Estimators 7.2.3 Bayes Estimators 7.2.4 The EM Algorithm 7.3 Methods of Evaluating Estimators 7.3.1 Mean Squared Error 7.3.2 Best Unbiased Estimators 7.3.3 Sufficiency and Unbiasedness 7.3.4 Loss Function Optimality 7.4 Miscellanea "],["hypothesis-testing.html", "8 Hypothesis Testing 8.1 Introduction 8.2 Methods of Finding Tests 8.3 Methods of Evaluating Tests 8.4 Miscellanea", " 8 Hypothesis Testing 8.1 Introduction 8.2 Methods of Finding Tests 8.2.1 Likelihood Ratio Tests 8.2.2 Bayesian Tests 8.2.3 Union-Intersection and Intersection-Union Tests 8.3 Methods of Evaluating Tests 8.3.1 Error Probabilities and the Power Function 8.3.2 Most Powerful Tests 8.3.3 Sizes of Union-Intersection and Intersection-Union Tests 8.3.4 p-Values 8.3.5 Loss Function Optimality 8.4 Miscellanea "],["interval-estimation.html", "9 Interval Estimation 9.1 Introduction 9.2 Methods of Finding Interval Estimators 9.3 Methods of Evaluating Interval Estimators 9.4 Miscllanea", " 9 Interval Estimation 9.1 Introduction 9.2 Methods of Finding Interval Estimators 9.2.1 Inverting a Test Statistic 9.2.2 Pivotal Quantities 9.2.3 Pivoting the CDF 9.2.4 Bayesian Intervals 9.3 Methods of Evaluating Interval Estimators 9.3.1 Size and Coverage Probability 9.3.2 Test-Related Optimality 9.3.3 Bayesian Optimality 9.3.4 Loss Function Optimality 9.4 Miscllanea "],["asymptotic-evaluations.html", "10 Asymptotic Evaluations 10.1 Point Estimation 10.2 Robustness 10.3 Hypothesis Testing 10.4 Interval Estimation 10.5 Miscellanea", " 10 Asymptotic Evaluations 10.1 Point Estimation 10.1.1 Consistency 10.1.2 Efficiency 10.1.3 Calculations and Comparisons 10.1.4 Bootstrap Standard Errors 10.2 Robustness 10.2.1 The Mean and the Median 10.2.2 M-Estimators 10.3 Hypothesis Testing 10.3.1 Asymptotic Distribution of LRTs 10.3.2 Other Large-Sample Tests 10.4 Interval Estimation 10.4.1 Approximate Maximum Likelihood Intervals 10.4.2 Other Large-Sample Intervals 10.5 Miscellanea "],["analysis-of-variance-and-regression.html", "11 Analysis of Variance and Regression 11.1 Introduction 11.2 Oneway Analysis of Variance 11.3 Simple Linear Regression 11.4 Miscellanea", " 11 Analysis of Variance and Regression 11.1 Introduction 11.2 Oneway Analysis of Variance 11.2.1 Model and Distribution Assumptions 11.2.2 The Classical ANOVA Hypothesis 11.2.3 Inferences Regarding Linear Combinations of Means 11.2.4 The ANOVA F Test 11.2.5 Simultaneous Estimation of Contrasts 11.2.6 Partitioning Sums of Squares 11.3 Simple Linear Regression 11.3.1 Least Squares: A Mathematical Solution 11.3.2 Best Linear Unbiased Estimators: A Statistical Solution 11.3.3 Models and Distribution Assumptions 11.3.4 Estimation and Testing with Normal Erros 11.3.5 Estimation and Prediction at a Specified x = x0 11.3.6 Simultaneous Estimation and Confidence Bands 11.4 Miscellanea "],["regression-models.html", "12 Regression Models 12.1 Introduction 12.2 Regression with Errors in Variables 12.3 Logistic Regression 12.4 Robust Regression 12.5 Miscellanea", " 12 Regression Models 12.1 Introduction 12.2 Regression with Errors in Variables 12.2.1 Functional and Structural Relationships 12.2.2 A Least Squares Solution 12.2.3 Maximum Likelihood Estimation 12.2.4 Confidence Sets 12.3 Logistic Regression 12.3.1 The Model 12.3.2 Estimation 12.4 Robust Regression 12.5 Miscellanea "]]
